{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ExponentialDS/portfolio/blob/master/Copy_of_CA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e480c9d84a20dbd6b3fb371fc85f352f",
          "grade": false,
          "grade_id": "cell-02adfcc9ad63a2ad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "CbE8t2I6o1hl"
      },
      "source": [
        "# ECMM441 Machine Vision\n",
        "\n",
        "## Course Assessment\n",
        "\n",
        "This is an semi-autogradable course assessment (CA) for the ECMM441 Machine Vision module, which represents 60% of the overall module assessment.\n",
        "\n",
        "This is an individual exercise and your attention is drawn to the College and University guidelines on collaboration and plagiarism, which are available from the University of Exeter [website](https://www.exeter.ac.uk/students/administration/complaintsandappeals/academicmisconduct/).\n",
        "\n",
        "**Important:**\n",
        "1. Do not change the name of this notebook and the containing folder. The notebook and the folder should respectively be named as **CA.ipynb** and **CA**.\n",
        "2. Do not add and remove/delete any cell. You can work on a draft notebook and only copy the functions/implementations here.\n",
        "3. Do not add your name or student code in the notebook or in the file name.\n",
        "4. Each question asks for one or more functions to be implemented.\n",
        "5. Each question is associated with appropriate marks and clearly specifies the marking criteria. Most of the questions have partial grading.\n",
        "6. Each question specifies a particular type of inputs and outputs which you should regard.\n",
        "7. Each question specifies data for your experimentation and test which you can consider.\n",
        "8. A hidden unit test is going to evaluate if all the desired properties of the required function(s) are met or not.\n",
        "9. If the test passes all the associated marks will be rewarded, if it fails 0 marks will be awarded.\n",
        "10. There is no restriction on the usage of any function from the packages from pip3 distribution.\n",
        "11. While uploading your work on EBART, please do not upload the EXCV10 and MaskedFace datasets you use for training your model, as the upload limit of EBART is set to 100MB and that cannot be changed. If you need to upload a file larger than 100MB limit, please upload that file in an external storage and put a link to that file in a README file to be uploaded with your submission. Please note that the external file should not be modified after the deadline, which will be strictly checked."
      ],
      "id": "CbE8t2I6o1hl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "98d247621f7edb42c61a1f5fa08d4352",
          "grade": false,
          "grade_id": "cell-e3e96c66c532b762",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "YfA5dp5So1hp"
      },
      "source": [
        "## Question 1 (3 marks)\n",
        "Write a function `add_gaussian_noise(im, m, std)` which will add Gaussian noise with mean `m` and standard deviation `std` to the input image `im` and will return the noisy image. Note that the output image must be of `float32` type and the pixel values should be in $[0, 1]$. (**Hint**: It is recommended to map the pixel values into floating point format (`float32`) with pixel values in [0.0, 1.0], then add the appropriate noise and then clip the values within [0.0, 1.0].)\n",
        "\n",
        "#### Inputs\n",
        "* `im` is a 3 dimensional numpy array of type `uint8` with values in $[0,255]$.\n",
        "* `m` is a real number.\n",
        "* `std` is a real number.\n",
        "\n",
        "#### Outputs\n",
        "* The expected output is a 3 dimensional numpy array of type `float32` with values in $[0, 1]$.\n",
        "\n",
        "#### Data\n",
        "* You can work with the image at `data/books.jpg`.\n",
        "\n",
        "#### Marking Criteria\n",
        "* The output with a particular `m` and `std` should exactly match with the correct noisy image with that `m` and `std` to obtain the full marks. There is no partial marking for this question."
      ],
      "id": "YfA5dp5So1hp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If in Colab, need to mount drive"
      ],
      "metadata": {
        "id": "20gcgnpzwsz5"
      },
      "id": "20gcgnpzwsz5"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "F1hnDsM6wxac",
        "outputId": "7b1f9b56-357b-4783-cd90-e3ca024f3b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F1hnDsM6wxac",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ee2911a89460f9a79ee530aabbe1622e",
          "grade": false,
          "grade_id": "cell-7eeea1af3cba818f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "QzV-5fIFo1hq"
      },
      "outputs": [],
      "source": [
        "def add_gaussian_noise(im, m, std):\n",
        "      \n",
        "    normalized_image = np.true_divide(im, 255, dtype=np.float32)\n",
        "    row,col,ch=normalized_image.shape\n",
        "    mean=m\n",
        "    var=std\n",
        "    sigma=std**0.5\n",
        "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
        "    gauss = gauss.reshape(row,col,ch)\n",
        "    noisy_gauss = normalized_image + gauss\n",
        "    noisy_gauss_clipped = np.clip(noisy_gauss, 0, 1)\n",
        "    a = np.float32(noisy_gauss_clipped)\n",
        "    return a\n"
      ],
      "id": "QzV-5fIFo1hq"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "551a5646967d5d80a93f1f908332b805",
          "grade": true,
          "grade_id": "cell-a77edaa5578e1b3e",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4FqgMTb1o1hr"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "4FqgMTb1o1hr"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6d7438df731fef80cde6bd2ee48b06bb",
          "grade": true,
          "grade_id": "cell-ad3e75b7c8a46e28",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "aog6gokro1hr"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "aog6gokro1hr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9486cdfc0ce4acd7a841d43b864087c8",
          "grade": false,
          "grade_id": "cell-1cef5e6785f36dd7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Mwu4E38Co1hr"
      },
      "source": [
        "## Question 2 (3 marks)\n",
        "Speckle noise is defined as multiplicative noise, having a granular pattern, it is the inherent property of Synthetic Aperture Radar (SAR) imagery. More details on Speckle noise can be found [here](https://en.wikipedia.org/wiki/Speckle_(interference)). Write a function `add_speckle_noise(im, m, std)` which will add Speckle noise with mean `m` and standard deviation `std` to the input image `im` and will return the noisy image. Note that the output image must be of `float32` type and the pixel values should be in $[0, 1]$. (**Hint**: It is recommended to map the pixel values into floating point format (`float32`) with pixel values in [0.0, 1.0], then add the appropriate noise and then clip the values within [0.0, 1.0].)\n",
        "\n",
        "#### Inputs\n",
        "* `im` is a 3 dimensional numpy array of type `uint8` with values in $[0,255]$.\n",
        "* `m` is a real number.\n",
        "* `std` is a real number.\n",
        "\n",
        "#### Outputs\n",
        "* The expected output is a 3 dimensional numpy array of type `float32` with values in $[0, 1]$.\n",
        "\n",
        "#### Data\n",
        "* You can work with the image at `data/books.jpg`.\n",
        "\n",
        "#### Marking Criteria\n",
        "* The output with a particular `m` and `std` should exactly match with the correct noisy image with that `m` and `std` to obtain the full marks. There is no partial marking for this question."
      ],
      "id": "Mwu4E38Co1hr"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a98a6114e438ab0248bfab8f74f459b4",
          "grade": false,
          "grade_id": "cell-4407a7529ab5b81e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "90JcGYqUo1hs"
      },
      "outputs": [],
      "source": [
        "# Speckle noise\n",
        "def add_speckle_noise(im, m, std):\n",
        "    \n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    mean=m\n",
        "    sigma=std\n",
        "   \n",
        "    normalized_image = np.true_divide(im, 255, dtype=np.float32)\n",
        "    row,col,ch=im.shape\n",
        "    gauss=np.random.randn(row,col,ch)\n",
        "    gauss = gauss.reshape(row,col,ch)\n",
        "    speckle_noisy = im + im + gauss\n",
        "    speckle_clipped = np.clip(speckle_noisy, 0, 1)\n",
        "    a = np.float32(speckle_clipped)\n",
        "    return a\n",
        "\n"
      ],
      "id": "90JcGYqUo1hs"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cc2c6b7e4931268c579597c589abfd3b",
          "grade": true,
          "grade_id": "cell-afda26557d5fb74d",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8CaCroFmo1ht"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "8CaCroFmo1ht"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "299060ae9c688c36ccf2612666888ca4",
          "grade": false,
          "grade_id": "cell-e3511b1295336825",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "YklrC2YHo1hu"
      },
      "source": [
        "## Question 3 (3 marks)\n",
        "Write a function `cal_image_hist(gr_im)` which will calculate the histogram of pixel intensities of a gray image `gr_im`. Note that the histogram will be a one dimensional array whose length must be equal to `v + 1`, where `v` is the maximum intensity value of `gr_im`.\n",
        "#### Inputs\n",
        "* `gr_im` is a 2 dimensional numpy array of type `uint8` with values in $[0,255]$.\n",
        "\n",
        "#### Outputs\n",
        "* The expected output is a 1 dimensional numpy array of type `int64`.\n",
        "\n",
        "#### Data\n",
        "* You can play with the image at `data/books.jpg`.\n",
        "\n",
        "#### Marking Criteria\n",
        "* The output should exactly match with the correct histogram of a given gray image `gr_im` to obtain the full marks. There is no partial marking for this question."
      ],
      "id": "YklrC2YHo1hu"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "10f7bfd7fbcbf9f096047fe4ec6315f0",
          "grade": false,
          "grade_id": "cell-f8f522d5df185ee4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "oUzfeDcPo1hu"
      },
      "outputs": [],
      "source": [
        "# Image histogram\n",
        "def cal_image_hist(gr_im):\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "     # image path \n",
        "    path = gr_im\n",
        "\n",
        "    # using imread()   \n",
        "    \n",
        "    #cv2.imshow('Cat',img)\n",
        "\n",
        "    dst = cv2.calcHist(path, [0], None, [256], [0,256])\n",
        "    dst = dst.reshape(-1,)\n",
        "    return np.int64(dst)\n",
        "\n",
        "    # plt.hist(img.ravel(),256,[0,256])\n",
        "    # plt.title('Histogram for gray scale image')\n",
        "    # plt.show()"
      ],
      "id": "oUzfeDcPo1hu"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "35e89447539e46a35163473264888ca6",
          "grade": true,
          "grade_id": "cell-424ed01ea55a463f",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "249tIO4fo1hv"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "249tIO4fo1hv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d0b1a9b8f712e1b78b9d6c3048add9da",
          "grade": false,
          "grade_id": "cell-c3bc76ebe55d35dc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qzXlRB9Uo1hv"
      },
      "source": [
        "## Question 4 (3 marks)\n",
        "Write a function `compute_gradient_magnitude(gr_im, kx, ky)` to compute gradient magnitude of the gray image `gr_im` with the horizontal kernel `kx` and vertical kernel `ky`.\n",
        "\n",
        "#### Inputs\n",
        "* `gr_im` is a 2 dimensional numpy array of data type `uint8` with values in $[0,255]$.\n",
        "* `kx` and `ky` are 2 dimensional numpy arrays of data type `uint8`.\n",
        "\n",
        "#### Outputs\n",
        "* The expected output is a 2 dimensional numpy array of the same shape as of `gr_im` and of data type `float64`.\n",
        "\n",
        "#### Data\n",
        "* You can work with the image at `data/shapes.png`.\n",
        "\n",
        "#### Marking Criteria\n",
        "* The output should exactly match with the correct gradient magnitude of a given gray image `gr_im` to obtain the full marks. There is no partial marking for this question."
      ],
      "id": "qzXlRB9Uo1hv"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b4960046eb6f43cead27141555a97002",
          "grade": false,
          "grade_id": "cell-eccc53aa72c6c5f0",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2fb8Izrto1hv"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage\n",
        "\n",
        "def compute_gradient_magnitude(gr_im, kx, ky):\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from scipy import ndimage\n",
        "\n",
        "    #I = cv2.imread(gr_im, 0).astype(np.float64)\n",
        "\n",
        "    \n",
        "\n",
        "    #-Derivative x\n",
        "    Kx = kx\n",
        "    Fx = ndimage.convolve(gr_im, Kx)\n",
        "\n",
        "    #-Derivative y\n",
        "    Ky = ky\n",
        "    Fy = ndimage.convolve(gr_im, Ky)\n",
        "\n",
        "    #-Gradient \n",
        "\n",
        "    #--Magnitute\n",
        "    magnitude = np.sqrt(Fx**2 + Fy**2) # G\n",
        "    # Limit to 255\n",
        "    new_arr = ((magnitude + 0.1) * (1/0.3) * 255).astype('uint8')\n",
        "    \n",
        "    return new_arr.astype('float64')"
      ],
      "id": "2fb8Izrto1hv"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e9a3e03ab148188a51d7e016ecfa27b7",
          "grade": true,
          "grade_id": "cell-3c5b1199737d8243",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "kgprtKAJo1hw"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "kgprtKAJo1hw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "681ae2d8125166fb0b39cdcd79c9ed59",
          "grade": false,
          "grade_id": "cell-9f8b99fca6851b1c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7D3Dewjoo1hw"
      },
      "source": [
        "## Question 5 (3 marks)\n",
        "Write a function `compute_gradient_direction(gr_im, kx, ky)` to compute direction of gradient in radians of the gray image `gr_im` with the horizontal kernel `kx` and vertical kernel `ky`.\n",
        "\n",
        "#### Inputs\n",
        "* `gr_im` is a 2 dimensional numpy array of data type `uint8` with values in $[0,255]$.\n",
        "* `kx` and `ky` are 2 dimensional numpy arrays of data type `uint8`.\n",
        "\n",
        "#### Outputs\n",
        "* The expected output is a 2 dimensional numpy array of same shape as of `gr_im` and of data type `float64`.\n",
        "\n",
        "#### Data\n",
        "* You can work with the image at `data/shapes.png`.\n",
        "\n",
        "#### Marking Criteria\n",
        "* The output should exactly match with the correct gradient direction in radians of a given gray image `gr_im` to obtain the full marks. There is no partial marking for this question."
      ],
      "id": "7D3Dewjoo1hw"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2f3220de8340968c8afbf10f6d0c622b",
          "grade": false,
          "grade_id": "cell-1d8d4d0d270a1ba5",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "HNFNKV1_o1hw"
      },
      "outputs": [],
      "source": [
        "# Image gradient magnitude\n",
        "def compute_gradient_direction(gr_im, kx, ky):\n",
        "    \n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from scipy import ndimage\n",
        "\n",
        "    #I = cv2.imread(gr_im, 0).astype(np.float64)\n",
        "\n",
        "    #-Derivative x\n",
        "    Kx = kx\n",
        "    Fx = ndimage.convolve(gr_im, Kx)\n",
        "\n",
        "    #-Derivative y\n",
        "    Ky = ky\n",
        "    Fy = ndimage.convolve(gr_im, Ky)\n",
        "\n",
        "    #-Gradient \n",
        "\n",
        "    #Direction\n",
        "    \n",
        "    orientation = np.arctan2(Fy, Fx) * (180 / np.pi) % 180\n",
        "\n",
        "    # Limit to 255\n",
        "    new_arr = ((orientation + 0.1) * (1/0.3) * 255).astype('uint8')\n",
        "    \n",
        "    return new_arr.astype('float64')"
      ],
      "id": "HNFNKV1_o1hw"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "482cb91ca2bca71b8ead2e1c33ca38fd",
          "grade": true,
          "grade_id": "cell-599d2d34653411a2",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fsEOSunZo1hx"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "fsEOSunZo1hx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7380062410568535a0d510ac890163d6",
          "grade": false,
          "grade_id": "cell-ae32b514c2f0feff",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qtVje7t_o1hx"
      },
      "source": [
        "## Question 6 (10 marks)\n",
        "Write a function `detect_harris_corner(im, ksize, sigmaX, sigmaY, k)` which will detect the corners in the image `im`. Here `ksize` is the kernel size for smoothing the image, `sigmaX` and `sigmaY` are respectively the standard deviations of the kernal along the horizontal and vertical direction, and `k` is the constant in the Harris criteria. Experiment with your corner detection function on the following image (located at `data/shapes.png`):\n",
        "\n",
        "<img src=\"data/shapes.png\" alt=\"Shapes\" width=\"300\"/>\n",
        "\n",
        "Adjust the parameters of your function so that it can detect all the corners in that image. Please feel free to change the given default parameters and set your best parameters as default. You must not resize the above image and note that the returned output should be an $N \\times 2$ array of type `int64`, where $N$ is the total number of existing corner points in the image; each row of that $N \\times 2$ array should be a Cartesian coordinate of the form $(x, y)$. Also please make sure that your function is rotation invariant which is the fundamental property of the Harris corner detection algorithm.\n",
        "\n",
        "#### Inputs\n",
        "* `im` is a 3 dimensional numpy array of type `uint8` with values in $[0,255]$.\n",
        "* `ksize` is an integer number.\n",
        "* `sigmaX` is an integer number.\n",
        "* `sigmaY` is an integer number.\n",
        "* `k` is a floating number.\n",
        "\n",
        "#### Outputs\n",
        "* The expected output is a 2 dimension numpy array of data type `int64` of size $N \\times 2$. Each row of that array should be a Cartesian coordinate of the form $(x, y)$.\n",
        "\n",
        "#### Data\n",
        "* You can work with the image at `data/shapes.png`.\n",
        "\n",
        "#### Marking Criteria\n",
        "* You will obtain full marks if your function can detect all the existing corners in the image, while the image is being rotated to different angles. There is partial marking for this question, which will depend on the performance of the function on that image rotated to different angles."
      ],
      "id": "qtVje7t_o1hx"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7f14b1555589fd343dcac394960797bb",
          "grade": false,
          "grade_id": "cell-64b592fa3da68f47",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "qz8FFgxAo1hx"
      },
      "outputs": [],
      "source": [
        "from skimage.feature import corner_peaks\n",
        "import cv2\n",
        "def detect_harris_corner(img, ksize=5, sigmaX=3, sigmaY=3, k=0.01):\n",
        "  # convert image to grayscale\n",
        "  #img = cv2.imread(img)\n",
        "  gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
        "  # light Gaussian smoothing\n",
        "  gray_img = cv2.GaussianBlur(gray_img, (ksize, ksize), sigmaX=sigmaX, sigmaY=sigmaY)\n",
        "  # construct the Sobel x-axis kernel\n",
        "  sobelX = np.array(([-1, 0, 1], [-2, 0, 2], [-1, 0, 1]), dtype=np.float)\n",
        "  # construct the Sobel y-axis kernel\n",
        "  sobelY = np.array(([-1, -2, -1], [0, 0, 0], [1, 2, 1]), dtype=np.float)\n",
        "  # convolution\n",
        "  I_x = cv2.filter2D(gray_img, -1, sobelX)\n",
        "  I_y = cv2.filter2D(gray_img, -1, sobelY)\n",
        "  # gradient covariances and light Gaussian smoothing\n",
        "  I_x_I_x = cv2.GaussianBlur(I_x*I_x, (ksize, ksize), sigmaX=sigmaX, sigmaY=sigmaY)\n",
        "  I_y_I_y = cv2.GaussianBlur(I_y*I_y, (ksize, ksize), sigmaX=sigmaX, sigmaY=sigmaY)\n",
        "  I_x_I_y = cv2.GaussianBlur(I_x*I_y, (ksize, ksize), sigmaX=sigmaX, sigmaY=sigmaY)\n",
        "  # determinant\n",
        "  detA = I_x_I_x * I_y_I_y - I_x_I_y ** 2\n",
        "  # trace\n",
        "  traceA = I_x_I_x + I_y_I_y\n",
        "  # Harris criteria\n",
        "  R = detA - k * traceA ** 2\n",
        "  corners = corner_peaks(R, min_distance=1, threshold_abs=1000000)\n",
        "  return corners\n",
        "    "
      ],
      "id": "qz8FFgxAo1hx"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1a11a0a7b4d55c41200acb966a391c0b",
          "grade": true,
          "grade_id": "cell-f8a94ba1f9bf95d7",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZZG21d5Do1hx"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "ZZG21d5Do1hx"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9c033716cf5b233afd5824b5c7204b15",
          "grade": true,
          "grade_id": "cell-f074d472db3c1382",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d_2ZacOzo1hy"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "d_2ZacOzo1hy"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "18cf8247fc651980b942b65a5e753b8f",
          "grade": true,
          "grade_id": "cell-0c61667b5eac0095",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "PnaeSBQJo1hy"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "PnaeSBQJo1hy"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "758713a32c41ceecece60e86c1af7f75",
          "grade": true,
          "grade_id": "cell-51d2fab12280c427",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "-ujWjphyo1hy"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "-ujWjphyo1hy"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ee2602a7f16da9a7b5f0dc3bca39eeaa",
          "grade": true,
          "grade_id": "cell-df725b5321c77ec8",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "K26igvk2o1hy"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "K26igvk2o1hy"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "648b0357ad2697c325c88e49a98a2e07",
          "grade": true,
          "grade_id": "cell-673193fb6357e2c9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "KJbd3_Tpo1hy"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "KJbd3_Tpo1hy"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cc07e20fb9d762cb021f06538bc63a1e",
          "grade": true,
          "grade_id": "cell-d1efeca335920d9c",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ny-u9A-Po1hz"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "ny-u9A-Po1hz"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e461f4e68336e3f03b5f6025d6206f47",
          "grade": true,
          "grade_id": "cell-f23b97663dd7e0b9",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9jW6BA1Vo1hz"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "9jW6BA1Vo1hz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "192855d529cfa1cabfb19960ec8d41fc",
          "grade": false,
          "grade_id": "cell-0513045479b5c601",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2H2oiX9Io1hz"
      },
      "source": [
        "## Question 7 (7 marks)\n",
        "Write a function `compute_sift(im, x, y, feature_width)` to compute a basic version of SIFT-like local features at the locations $(x, y)$ of the RGB image `im` as described in the lecture materials and chapter 7.1.2 of the 2nd edition of Szeliski's book. The parameter `feature_width` is an integer representing the local feature width in pixels. You can assume that `feature_width` will be a multiple of 4 (i.e. every cell of your local SIFT-like feature will have an integer width and height). This is the initial window size you examine around each keypoint. Your implemented function should return a numpy array of shape $k \\times 128$, where $k$ is the number of keypoints $(x, y)$ input to the function.\n",
        "\n",
        "<img src=\"data/notre_dame_interest_points.png\" alt=\"Interest Points\" width=\"300\"/>\n",
        "\n",
        "Please feel free to follow all the minute details of the [SIFT paper](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf) in your implementation, but please note that your implementation does not need to exactly match all the details to achieve a good performance. Instead a basic version of SIFT implementation is asked in this exercise, which should achieve a reasonable result. The following three steps could be considered as the basic steps: (1) a $4 \\times 4$ grid of cells, each feature_width/4. It is simply the terminology used in the feature literature to describe the spatial bins where gradient distributions will be described. (2) each cell should have a histogram of the local distribution of gradients in $8$ orientations. Appending these histograms together will give you $4 \\times 4 \\times 8 = 128$ dimensions. (3) Each feature should be normalized to unit length.\n",
        "\n",
        "#### Inputs\n",
        "* `im` is a 3 dimensional numpy array of data type `uint8` with values in $[0,255]$.\n",
        "* `x` is a 2 dimensional numpy array of data type `float64` with shape $k \\times 1$.\n",
        "* `y` is a 2 dimensional numpy array of data type `float64` with shape $k \\times 1$.\n",
        "* `feature_width` is an integer.\n",
        "\n",
        "#### Outputs\n",
        "* The expected output is a 2 dimensional numpy array of data type `float64` with shape $k \\times d$, where $d=128$ is the length of the SIFT feature vector.\n",
        "\n",
        "#### Data\n",
        "* You can tune your algorithm/parameters with the image at `data/notre_dame_1.jpg` and interest points at `data/notre_dame_1_to_notre_dame_2.pkl`.\n",
        "\n",
        "#### Marking Criteria\n",
        "* You will get full marks if your output is shape wise consistent with the expected output. This function will further be tested together with the feature matching function to be implemented in the next question. There is no partial marking for this question."
      ],
      "id": "2H2oiX9Io1hz"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5f4f2f58e55769400b85e8412cd560f8",
          "grade": false,
          "grade_id": "cell-a060cf9577bd1c4b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "5koyRzDuo1hz"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def compute_sift(img, x, y, feature_width=16, scales=None):\n",
        "    import numpy as np\n",
        "    import math \n",
        "    #assert img.ndim == 2, 'Image must be grayscale'\n",
        "    \n",
        "    #img = cv2.imread(img)\n",
        "    img_u8 = img.astype(np.uint8)\n",
        "    # Gaussian smoothing\n",
        "    img = cv2.GaussianBlur(img_u8, (3, 3), 2)\n",
        "\n",
        "    # get sobel filters\n",
        "    I_x = cv2.Sobel(img_u8, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    I_y = cv2.Sobel(img_u8, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "    \n",
        "    # compute angles and magnitudes of the image\n",
        "    angles = np.arctan2(I_y, I_x)\n",
        "    magnitudes = np.sqrt(I_x ** 2 + I_y ** 2)\n",
        "\n",
        "    # allocate memory\n",
        "    features = np.zeros((x.shape[0], 128))\n",
        "\n",
        "    step = feature_width // 4\n",
        "    win_rng = feature_width // 2\n",
        "\n",
        "    # go through each key point\n",
        "    for i in range(x.shape[0]):\n",
        "        xi = int(x[i])\n",
        "        yi = int(y[i])\n",
        "        # get patch\n",
        "        angles_patch = angles[yi - win_rng : yi + win_rng, xi - win_rng : xi + win_rng]\n",
        "        magnitudes_patch = magnitudes[yi - win_rng : yi + win_rng, xi - win_rng : xi + win_rng]\n",
        "        sift_features = []\n",
        "        # use patch for each key point\n",
        "        for j in range(0, feature_width, step):\n",
        "            for k in range(0, feature_width, step):\n",
        "                # get bins for each patch\n",
        "                angles_patch_bin = angles_patch[j : j + step, k : k + step]\n",
        "                magnitudes_patch_bin = magnitudes_patch[j : j + step, k : k + step]\n",
        "                # compute histogram and normalize\n",
        "                hist, _ = np.histogram(angles_patch_bin, bins=8, range=(-math.pi, math.pi), weights=magnitudes_patch_bin)\n",
        "                sift_features.extend(hist)\n",
        "        sift_features = np.array(sift_features)\n",
        "        features[i, :] = sift_features\n",
        "    features = features / (np.sum(features, axis=1, keepdims=True) + 0.0001)\n",
        "    return features"
      ],
      "id": "5koyRzDuo1hz"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bc1e7c88c7950cb798f37665ea6c0f92",
          "grade": true,
          "grade_id": "cell-7b4c98259bd001ef",
          "locked": true,
          "points": 7,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Z6nsAynpo1h0"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "Z6nsAynpo1h0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d5e122d50a42ae9c07aa642990a79696",
          "grade": false,
          "grade_id": "cell-db113289337db0ed",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "D__qrgGXo1h0"
      },
      "source": [
        "## Question 8 (11 marks)\n",
        "Write a function `match_features(features1, features2, x1, y1, x2, y2, threshold)` to implement the \"ratio test\" or \"nearest neighbor distance ratio test\" method of matching two sets of local features `features1` at the locations `(x1, y1)` and `features2` at the locations `(x2, y2)` as described in the lecture materials and in the chapter 7.1.3 of the 2nd edition of Szeliski's book.\n",
        "\n",
        "<img src=\"data/notre_dame_correspondance.png\" alt=\"Feature Matching\" width=\"500\"/>\n",
        "\n",
        "The parameters `features1` and `features2` are numpy arrays of shape $k \\times 128$, each representing one set of features. `x1` and `x2` are two numpy arrays of shape $k \\times 1$ respectively containing the x-locations of `features1` and `features2`. `y1` and `y2` are two numpy arrays of shape $k \\times 1$ respcectively containing the y-locations of `features1` and `features2`. `threshold` is another parameter that validates matches based on the ratio test explained in the lecture or in the book of Richard Szeliski (equation 7.18 in section 7.1.3). Your function should return two outputs: `matches` and `confidences`, where `matches` is a numpy array of shape $n \\times 2$, where $n$ is the number of matches. The first column of `matches` is an index in `features1`, and the second column is an index in `features2`. `confidences` is a numpy array of shape $k \\times 1$ with the real valued confidence for every match.\n",
        "\n",
        "This function does not need to be symmetric (e.g. it can produce different numbers of matches depending on the order of the arguments). To start with, simply implement the \"ratio test\", equation 7.18 in section 7.1.3 of Szeliski. There are a lot of repetitive features in these images, and all of their descriptors will look similar. The ratio test helps us resolve this issue (also see Figure 11 of David Lowe's [IJCV paper](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf). Please try to tune your SIFT descriptors and matching algorithm together to obtain a better matching score. You can use the images and correspondences below to tune your algorithm.\n",
        "\n",
        "#### Inputs\n",
        "* `features1` is a 2 dimensional numpy array of data type `float64` with shape $m \\times d$.\n",
        "* `features2` is a 2 dimensional numpy array of data type `float64` with shape $n \\times d$.\n",
        "* `x1` is a 2 dimensional numpy array of data type `float64` with shape $m \\times 1$.\n",
        "* `y1` is a 2 dimensional numpy array of data type `float64` with shape $m \\times 1$.\n",
        "* `x2` is a 2 dimensional numpy array of data type `float64` with shape $n \\times 1$.\n",
        "* `y2` is a 2 dimensional numpy array of data type `float64` with shape $n \\times 1$.\n",
        "* `threshold` is a real number of data type `float64`.\n",
        "\n",
        "#### Outputs\n",
        "* `matches` is a 2 dimensional numpy array of data type `int64`.\n",
        "* `confidences` is a 1 dimensional numpy array of data type `float64`.\n",
        "\n",
        "#### Data\n",
        "* You can tune your algorithm on the images at `data/notre_dame_1.jpg` and `data/notre_dame_2.jpg`, and interest points at `data/notre_dame_1_to_notre_dame_2.pkl` and also on the images at `data/mount_rushmore_1.jpg` and `data/mount_rushmore_2.jpg`, and interest points at `data/mount_rushmore_1_to_mount_rushmore_2.pkl`. Note that the corresponding points within the pickle files are the matching points.\n",
        "\n",
        "#### Marking Criteria\n",
        "* The marking will be based on matching accuracy obtained by the feature description and matching algorithm implemented by you respectively in the previous and this question. There are two test cases (5 marks each) with two different pairs of images and corresponding points, which are provided in the Data section. You will obtain 60% marks if your algorithm can obtain matching accuracy greater than or equal to 50%, 80% marks if your algorithm obtains 70% accuracy or more, and full marks if your algorithm secures 90% matching accuracy or more. You will not obtain any mark if your algorithm can not achieve 50% matching accuracy."
      ],
      "id": "D__qrgGXo1h0"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "63f75fa3e3abf675fd9cda01849a5661",
          "grade": false,
          "grade_id": "cell-9a95f2fdcb4cf7af",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "VH7TNjw-o1h0"
      },
      "outputs": [],
      "source": [
        "def show_interest_points(img, X, Y):\n",
        "    \"\"\"\n",
        "    Visualized interest points on an image with random colors\n",
        "\n",
        "    Args:\n",
        "    - img: A numpy array of shape (M,N,C)\n",
        "    - X: A numpy array of shape (k,) containing x-locations of interest points\n",
        "    - Y: A numpy array of shape (k,) containing y-locations of interest points\n",
        "\n",
        "    Returns:\n",
        "    - newImg: A numpy array of shape (M,N,C) showing the original image with\n",
        "            colored circles at keypoints plotted on top of it\n",
        "    \"\"\"\n",
        "    newImg = img.copy()\n",
        "    for x, y in zip(X.astype(int), Y.astype(int)):\n",
        "        cur_color = np.random.rand(3)\n",
        "        newImg = cv2.circle(newImg, (x, y), 20, cur_color, -1, cv2.LINE_AA)\n",
        "    return newImg\n",
        "\n",
        "def show_correspondence_circles(imgA, imgB, X1, Y1, X2, Y2):\n",
        "    \"\"\"\n",
        "    Visualizes corresponding points between two images by plotting circles at\n",
        "    each correspondence location. Corresponding points will have the same random color.\n",
        "\n",
        "    Args:\n",
        "    - imgA: A numpy array of shape (M,N,3)\n",
        "    - imgB: A numpy array of shape (D,E,3)\n",
        "    - x1: A numpy array of shape (k,) containing x-locations of keypoints in imgA\n",
        "    - y1: A numpy array of shape (k,) containing y-locations of keypoints in imgA\n",
        "    - x2: A numpy array of shape (j,) containing x-locations of keypoints in imgB\n",
        "    - y2: A numpy array of shape (j,) containing y-locations of keypoints in imgB\n",
        "\n",
        "    Returns:\n",
        "    - newImg: A numpy array of shape (max(M,D), N+E, 3)\n",
        "    \"\"\"\n",
        "    radius_circle = 10\n",
        "    newImg = hstack_images(imgA, imgB)\n",
        "    shiftX = imgA.shape[1]\n",
        "    X1 = X1.astype(np.int)\n",
        "    Y1 = Y1.astype(np.int)\n",
        "    X2 = X2.astype(np.int)\n",
        "    Y2 = Y2.astype(np.int)\n",
        "\n",
        "    for x1, y1, x2, y2 in zip(X1, Y1, X2, Y2):\n",
        "        cur_color = np.random.rand(3)\n",
        "        green = (0, 1, 0)\n",
        "        newImg = cv2.circle(newImg, (x1, y1), radius_circle, cur_color, -1, cv2.LINE_AA)\n",
        "        newImg = cv2.circle(newImg, (x1, y1), radius_circle, green, 2, cv2.LINE_AA)\n",
        "        newImg = cv2.circle(newImg, (x2+shiftX, y2), radius_circle, cur_color, -1, cv2.LINE_AA)\n",
        "        newImg = cv2.circle(newImg, (x2+shiftX, y2), radius_circle, green, 2, cv2.LINE_AA)\n",
        "\n",
        "    return newImg\n",
        "\n",
        "def show_correspondence_lines(imgA, imgB, X1, Y1, X2, Y2, line_colors=None):\n",
        "    \"\"\"\n",
        "    Visualizes corresponding points between two images by drawing a line segment\n",
        "    between the two images for each (x1,y1) (x2,y2) pair.\n",
        "\n",
        "    Args:\n",
        "    - imgA: A numpy array of shape (M,N,3)\n",
        "    - imgB: A numpy array of shape (D,E,3)\n",
        "    - x1: A numpy array of shape (k,) containing x-locations of keypoints in imgA\n",
        "    - y1: A numpy array of shape (k,) containing y-locations of keypoints in imgA\n",
        "    - x2: A numpy array of shape (j,) containing x-locations of keypoints in imgB\n",
        "    - y2: A numpy array of shape (j,) containing y-locations of keypoints in imgB\n",
        "    - line_colors: A numpy array of shape (N x 3) with colors of correspondence lines (optional)\n",
        "\n",
        "    Returns:\n",
        "    - newImg: A numpy array of shape (max(M,D), N+E, 3)\n",
        "    \"\"\"\n",
        "    radius_circle = 10\n",
        "    radius_half_circle = 5\n",
        "    newImg = hstack_images(imgA, imgB)\n",
        "    shiftX = imgA.shape[1]\n",
        "    X1 = X1.astype(np.int)\n",
        "    Y1 = Y1.astype(np.int)\n",
        "    X2 = X2.astype(np.int)\n",
        "    Y2 = Y2.astype(np.int)\n",
        "\n",
        "    dot_colors = np.random.rand(len(X1), 3)\n",
        "    if line_colors is None:\n",
        "        line_colors = dot_colors\n",
        "\n",
        "    for x1, y1, x2, y2, dot_color, line_color in zip(X1, Y1, X2, Y2, dot_colors, line_colors):\n",
        "        newImg = cv2.circle(newImg, (x1, y1), radius_circle, dot_color, -1)\n",
        "        newImg = cv2.circle(newImg, (x2+shiftX, y2), radius_circle, dot_color, -1)\n",
        "        newImg = cv2.line(newImg, (x1, y1), (x2+shiftX, y2), line_color, 2, cv2.LINE_AA)\n",
        "    return newImg\n",
        "\n",
        "def hstack_images(imgA, imgB):\n",
        "    \"\"\"\n",
        "    Stacks 2 images side-by-side and creates one combined image.\n",
        "\n",
        "    Args:\n",
        "    - imgA: A numpy array of shape (M,N,3) representing rgb image\n",
        "    - imgB: A numpy array of shape (D,E,3) representing rgb image\n",
        "\n",
        "    Returns:\n",
        "    - newImg: A numpy array of shape (max(M,D), N+E, 3)\n",
        "    \"\"\"\n",
        "    Height = max(imgA.shape[0], imgB.shape[0])\n",
        "    Width  = imgA.shape[1] + imgB.shape[1]\n",
        "\n",
        "    newImg = np.zeros((Height, Width, 3), dtype=imgA.dtype)\n",
        "    newImg[:imgA.shape[0], :imgA.shape[1], :] = imgA\n",
        "    newImg[:imgB.shape[0], imgA.shape[1]:, :] = imgB\n",
        "\n",
        "    return newImg\n",
        "\n",
        "def load_corr_pkl_file(corr_fpath):\n",
        "    \"\"\"\n",
        "    Load ground truth correspondences from a pickle (.pkl) file.\n",
        "    \"\"\"\n",
        "    with open(corr_fpath, 'rb') as f:\n",
        "        d = pickle.load(f, encoding='latin1')\n",
        "    x1 = d['x1'].squeeze()\n",
        "    y1 = d['y1'].squeeze()\n",
        "    x2 = d['x2'].squeeze()\n",
        "    y2 = d['y2'].squeeze()\n",
        "\n",
        "    return x1,y1,x2,y2\n",
        "\n",
        "def evaluate_correspondence(imgA, imgB, corr_fpath, scale_factor, x1_est, y1_est,\n",
        "        x2_est, y2_est, confidences=None, num_req_matches=100):\n",
        "    \"\"\"\n",
        "    Function to evaluate estimated correspondences against ground truth.\n",
        "\n",
        "    The evaluation requires 100 matches to receive full credit\n",
        "    when num_req_matches=100 because we define accuracy as:\n",
        "\n",
        "    Accuracy = (true_pos)/(true_pos+false_pos) * min(num_matches,num_req_matches)/num_req_matches\n",
        "\n",
        "    Args:\n",
        "    - imgA: A numpy array of shape (M,N,C) representing a first image\n",
        "    - imgB: A numpy array of shape (M,N,C) representing a second image\n",
        "    - corr_fpath: string, representing a filepath to a .pkl file containing ground truth correspondences\n",
        "    - scale_factor: scale factor on the size of the images\n",
        "    - x1_est: A numpy array of shape (k,) containing estimated x-coordinates of imgA correspondence pts\n",
        "    - y1_est: A numpy array of shape (k,) containing estimated y-coordinates of imgA correspondence pts\n",
        "    - x2_est: A numpy array of shape (k,) containing estimated x-coordinates of imgB correspondence pts\n",
        "    - y2_est: A numpy array of shape (k,) containing estimated y-coordinates of imgB correspondence pts\n",
        "    - confidences: (optional) confidence values in the matches\n",
        "    \"\"\"\n",
        "    if confidences is None:\n",
        "        confidences = np.random.rand(len(x1_est))\n",
        "        confidences /= np.max(confidences)\n",
        "\n",
        "    x1_est = x1_est.squeeze() / scale_factor\n",
        "    y1_est = y1_est.squeeze() / scale_factor\n",
        "    x2_est = x2_est.squeeze() / scale_factor\n",
        "    y2_est = y2_est.squeeze() / scale_factor\n",
        "\n",
        "    num_matches = x1_est.shape[0]\n",
        "\n",
        "    x1,y1,x2,y2 = load_corr_pkl_file(corr_fpath)\n",
        "\n",
        "    good_matches = [False for _ in range(len(x1_est))]\n",
        "    # array marking which GT pairs are already matched\n",
        "    matched = [False for _ in range(len(x1))]\n",
        "\n",
        "    # iterate through estimated pairs in decreasing order of confidence\n",
        "    priority = np.argsort(-confidences)\n",
        "    for i in priority:\n",
        "        # print('Examining ({:4.0f}, {:4.0f}) to ({:4.0f}, {:4.0f})'.format(\n",
        "        #     x1_est[i], y1_est[i], x2_est[i], y2_est[i]))\n",
        "        cur_offset = np.asarray([x1_est[i]-x2_est[i], y1_est[i]-y2_est[i]])\n",
        "        # for each x1_est find nearest ground truth point in x1\n",
        "        dists = np.linalg.norm(np.vstack((x1_est[i]-x1, y1_est[i]-y1)), axis=0)\n",
        "        best_matches = np.argsort(dists)\n",
        "\n",
        "        # find the best match that is not taken yet\n",
        "        for match_idx in best_matches:\n",
        "            if not matched[match_idx]:\n",
        "                break\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # A match is good only if\n",
        "        # (1) An unmatched GT point exists within 150 pixels, and\n",
        "        # (2) GT correspondence offset is within 25 pixels of estimated\n",
        "        #     correspondence offset\n",
        "        gt_offset = np.asarray([x1[match_idx]-x2[match_idx],\n",
        "            y1[match_idx]-y2[match_idx]])\n",
        "        offset_dist = np.linalg.norm(cur_offset-gt_offset)\n",
        "        if (dists[match_idx] < 150.0) and (offset_dist < 25):\n",
        "            good_matches[i] = True\n",
        "            print('Correct')\n",
        "        else:\n",
        "            print('Incorrect')\n",
        "\n",
        "    print('You found {}/{} required matches'.format(num_matches, num_req_matches))\n",
        "    accuracy = np.mean(good_matches) * min(num_matches, num_req_matches)*1./num_req_matches\n",
        "    print('Accuracy = {:f}'.format(accuracy))\n",
        "    green = np.asarray([0, 1, 0], dtype=float)\n",
        "    red = np.asarray([1, 0, 0], dtype=float)\n",
        "    line_colors = np.asarray([green if m else red for m in good_matches])\n",
        "\n",
        "    return accuracy, show_correspondence_lines(imgA, imgB,\n",
        "                                               x1_est*scale_factor, y1_est*scale_factor,\n",
        "                                               x2_est*scale_factor, y2_est*scale_factor,\n",
        "                                               line_colors)\n",
        "    \n",
        "\n",
        "import pickle\n",
        "def cheat_interest_points(eval_file, scale_factor):\n",
        "    \"\"\"\n",
        "    This function is provided for development and debugging but cannot be used in\n",
        "    the final handin. It 'cheats' by generating interest points from known\n",
        "    correspondences. It will only work for the 3 image pairs with known\n",
        "    correspondences.\n",
        "\n",
        "    Args:\n",
        "    - eval_file: string representing the file path to the list of known correspondences\n",
        "    - scale_factor: Python float representing the scale needed to map from the original\n",
        "            image coordinates to the resolution being used for the current experiment.\n",
        "\n",
        "    Returns:\n",
        "    - x1: A numpy array of shape (k,) containing ground truth x-coordinates of imgA correspondence pts\n",
        "    - y1: A numpy array of shape (k,) containing ground truth y-coordinates of imgA correspondence pts\n",
        "    - x2: A numpy array of shape (k,) containing ground truth x-coordinates of imgB correspondence pts\n",
        "    - y2: A numpy array of shape (k,) containing ground truth y-coordinates of imgB correspondence pts\n",
        "    \"\"\"\n",
        "    with open(eval_file, 'rb') as f:\n",
        "        d = pickle.load(f, encoding='latin1')\n",
        "\n",
        "    return d['x1'] * scale_factor, d['y1'] * scale_factor, d['x2'] * scale_factor,\\\n",
        "                    d['y2'] * scale_factor\n",
        "\n",
        "\n",
        "import cv2\n",
        "\n",
        "def compute_sift(img, x, y, feature_width=16, scales=None):\n",
        "    import numpy as np\n",
        "    import math \n",
        "    #assert img.ndim == 2, 'Image must be grayscale'\n",
        "    \n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    img_u8 = img.astype(np.uint8)\n",
        "    # Gaussian smoothing\n",
        "    img = cv2.GaussianBlur(img_u8, (3, 3), 2)\n",
        "\n",
        "    # get sobel filters\n",
        "    I_x = cv2.Sobel(img_u8, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    I_y = cv2.Sobel(img_u8, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "    \n",
        "    # compute angles and magnitudes of the image\n",
        "    angles = np.arctan2(I_y, I_x)\n",
        "    magnitudes = np.sqrt(I_x ** 2 + I_y ** 2)\n",
        "\n",
        "    # allocate memory\n",
        "    features = np.zeros((x.shape[0], 128))\n",
        "\n",
        "    step = feature_width // 4\n",
        "    win_rng = feature_width // 2\n",
        "\n",
        "    # go through each key point\n",
        "    for i in range(x.shape[0]):\n",
        "        xi = int(x[i])\n",
        "        yi = int(y[i])\n",
        "        # get patch\n",
        "        angles_patch = angles[yi - win_rng : yi + win_rng, xi - win_rng : xi + win_rng]\n",
        "        magnitudes_patch = magnitudes[yi - win_rng : yi + win_rng, xi - win_rng : xi + win_rng]\n",
        "        sift_features = []\n",
        "        # use patch for each key point\n",
        "        for j in range(0, feature_width, step):\n",
        "            for k in range(0, feature_width, step):\n",
        "                # get bins for each patch\n",
        "                angles_patch_bin = angles_patch[j : j + step, k : k + step]\n",
        "                magnitudes_patch_bin = magnitudes_patch[j : j + step, k : k + step]\n",
        "                # compute histogram and normalize\n",
        "                hist, _ = np.histogram(angles_patch_bin, bins=8, range=(-math.pi, math.pi), weights=magnitudes_patch_bin)\n",
        "                sift_features.extend(hist)\n",
        "        sift_features = np.array(sift_features)\n",
        "        features[i, :] = sift_features\n",
        "    features = features / (np.sum(features, axis=1, keepdims=True) + 0.0001)\n",
        "    return features\n",
        "\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import numpy as np\n",
        "\n",
        "def match_features(features1, features2, x1, y1, x2, y2, threshold=1.0):\n",
        "\n",
        "    # euclidean distances\n",
        "    distances = euclidean_distances(features1, features2)\n",
        "\n",
        "    # sorted distances\n",
        "    indices = np.argsort(distances, axis=1)\n",
        "    sorted_distances = np.take_along_axis(distances, indices, axis=1)\n",
        "\n",
        "    # NNDR\n",
        "    scores = sorted_distances[:, 0] / sorted_distances[:, 1]\n",
        "\n",
        "    # where scores < threshold\n",
        "    idx = scores < threshold\n",
        "\n",
        "    # confidence\n",
        "    confidences = 1 / scores[idx]\n",
        "\n",
        "    k = confidences.shape[0]\n",
        "    matches = np.zeros((k, 2), dtype=int)\n",
        "    \n",
        "    # matches for which we have score or distance < threshold\n",
        "    matches[:, 0] = np.where(idx)[0]\n",
        "    matches[:, 1] = indices[idx, 0]\n",
        "\n",
        "    # arrange the matches and the confidences in descending order\n",
        "    idx = (-confidences).argsort()\n",
        "    matches = matches[idx, :]\n",
        "    confidences = confidences[idx]\n",
        "\n",
        "    return matches, confidences"
      ],
      "id": "VH7TNjw-o1h0"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "13a0ebd6c76e5c44149379447cf1272c",
          "grade": true,
          "grade_id": "cell-321a8f0b2c0f9ef9",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "texg5IxGo1h1"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "texg5IxGo1h1"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a3d943f3da3580737eecc7f605f8c6fc",
          "grade": true,
          "grade_id": "cell-e3246502d1707318",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "45NIEHWlo1h1"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "45NIEHWlo1h1"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b5e204294b4f5f893c140bf76d2af93",
          "grade": true,
          "grade_id": "cell-e0b2bc03a9adc29a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "N5WgKKxfo1h2"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "N5WgKKxfo1h2"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4d00c1283c7670542fed56b26ae94b6e",
          "grade": true,
          "grade_id": "cell-30926a4f2a0dc63a",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "c-vfrglVo1h2"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "c-vfrglVo1h2"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "80c8f28edf47259036f8913272e2cee1",
          "grade": true,
          "grade_id": "cell-742bd8eefb42996e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Ws7XipgIo1h2"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "Ws7XipgIo1h2"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "78c39ad170b2cfed36e9ff3e7e14235a",
          "grade": true,
          "grade_id": "cell-c3eed272abd24f64",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Dg0yUroVo1h2"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "Dg0yUroVo1h2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3c04083b5fd2990ad0b0796933c7d9c2",
          "grade": false,
          "grade_id": "cell-6adcd7879c172b75",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "bbY8oOsho1h2"
      },
      "source": [
        "## Question 9 (10 marks)\n",
        "Write a function `make_bovw_spatial_histogram(im, locations, clusters, division)` to create bag of visual words representation of an image `im` whose features are located at `locations` and the quantized labels of those features are stored in `clusters`. You have to build the histogram based on the division information provided in `division`. For example, if `division = [2, 3]`, you have to imagine dividing the image along Y-axis in $2$ parts and along X-axis in $3$ parts (as shown in the right most figure below), else if `division = [2, 2]`, you have to imagine dividing the image in $2$ parts along both the axes, else if `division = [1, 1]`, you just compute the bag-of-visual-words histogram on the entire image without dividing into any parts.\n",
        "\n",
        "<img src=\"data/spatial_histogram.png\" alt=\"Spatial Histogram\" width=\"1000\"/>\n",
        "\n",
        "#### Inputs\n",
        "* `im` is a 3 dimensional numpy array of data type `uint8`.\n",
        "* `locations` is a 2 dimensional numpy array of shape $N \\times 2$ of data type `int64`, whose each row is a Cartesian coordinate $(x,y)$.\n",
        "* `clusters` is a 1 dimensional numpy array of shape $(N,)$ of data type `int64`, whose each element indicates the quantized cluster id. Please note that the i$^{th}$ point in `locations` corresponds to the i$^{th}$ cluster id in `clusters`.\n",
        "* `division` is a list of integer of length 2.\n",
        "\n",
        "#### Outputs\n",
        "* This function should return a 1 dimensional numpy array of data type `int64`.\n",
        "\n",
        "#### Data\n",
        "* There is no specific data for this question. However, you can create data on one of the images available inside the `data` folder.\n",
        "\n",
        "#### Marking Criteria\n",
        "* There are four test cases which will call the above function to calculate bag-of-visual-words spatial histograms on the image `im` imagining its coarse and fine divisions which will be provided while calling the function. In each test case, your spatial histogram should be exactly matched with the correct spatial histogram to obtain the full marks. Coarser test cases contain lower weightage compared to their finer counter parts."
      ],
      "id": "bbY8oOsho1h2"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3ef10999fcd92b1833108194654161d4",
          "grade": false,
          "grade_id": "cell-0e96f0362680e419",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "m8wxFzRxo1h2"
      },
      "outputs": [],
      "source": [
        "# Spatial bag of visual words histogram\n",
        "def make_bovw_spatial_histogram(im, locations, clusters, division):\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    # get number of rows and columns for each cell after division\n",
        "    h, w = im.shape[:2]\n",
        "    nrows = h//division[0]\n",
        "    ncols = w//division[1]\n",
        "\n",
        "    # quantiles : to save histogram value of every cell\n",
        "    quantiles = []\n",
        "    for i in range(division[0]):\n",
        "      for j in range(division[1]):\n",
        "\n",
        "        # create sub quantile array to save histogram of current cell\n",
        "        sub_quantile = np.zeros((max(clusters)+1,))\n",
        "\n",
        "        # get xmin, xmax, ymin, ymax\n",
        "        ymin, ymax = i * nrows, (i+1)* nrows\n",
        "        xmin, xmax = j * ncols, (j+1) * ncols\n",
        "\n",
        "        # get indexes of locations with values between xmin, xmax, ymin, ymax\n",
        "        idx = np.where((locations[:,0]>=xmin) & (locations[:,0]<xmax) & (locations[:,1] >= ymin) & (locations[:,1] < ymax))\n",
        "\n",
        "        # pick values of clusters for given index and add it to sub_quantile array\n",
        "        for _class in clusters[idx[0]]:\n",
        "          sub_quantile[_class]+=1\n",
        "\n",
        "        # add this subquantile array to main list \n",
        "        quantiles.extend(sub_quantile.tolist())\n",
        "\n",
        "    # return array of quantiles\n",
        "    return np.array(quantiles).astype(np.int64)\n",
        "    "
      ],
      "id": "m8wxFzRxo1h2"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "60a71b53727f3a9aa4b5e80e77e753ac",
          "grade": true,
          "grade_id": "cell-a60e8d2f1ae4e282",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0cd4V52Zo1h3"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "0cd4V52Zo1h3"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4235b068b23d4beaf130232d07793cb3",
          "grade": true,
          "grade_id": "cell-49e01874c90ffaa9",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "j00boskro1h3"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "j00boskro1h3"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "afa091ea9b4a376a13c5659b0775cef8",
          "grade": true,
          "grade_id": "cell-59db309d7efddab7",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "D8NFYrwOo1h3"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "D8NFYrwOo1h3"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6fe5f06be7bb7dc0a97665b5603950aa",
          "grade": true,
          "grade_id": "cell-ada8a90ac0f97002",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "xkj2wUWJo1h3"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "xkj2wUWJo1h3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e364610bdf392cbc47df9d72fa038ecd",
          "grade": false,
          "grade_id": "cell-d44d6af26596e5be",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ETSxVVuBo1h3"
      },
      "source": [
        "## Question 10 (4 marks)\n",
        "Write a function `histogram_intersection_kernel(X, Y)` to compute Histogram Intersection Kernel which is also known as the Min Kernel and is calculated by\n",
        "$$k(x, y)=\\sum_{i=1}^d \\min(x_i, y_i)$$\n",
        "where $d$ is the length of the feature vector.\n",
        "\n",
        "#### Inputs\n",
        "* `X` and `Y` are 2 dimensional numpy arrays of shape $M \\times d$ and $N \\times d$ respectively of data type `int64`.\n",
        "\n",
        "#### Outputs\n",
        "* This function should return a 2 dimensional numpy array of shape $M \\times N$ of data type `float64`.\n",
        "\n",
        "#### Data\n",
        "* There is no specific data for this question. However, you can create your own data `X` and `Y` satisfying the input criteria.\n",
        "\n",
        "#### Marking Criteria\n",
        "* You will obtain full marks if and only if the kernel matrix calculated by your function exactly matches with the correct one. There is no partial marking for this question."
      ],
      "id": "ETSxVVuBo1h3"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bb0e5a0501f081c8f0f8678abdb2900c",
          "grade": false,
          "grade_id": "cell-ea9f47767182146f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "W8Psr-zYo1h3"
      },
      "outputs": [],
      "source": [
        "# Histogram intersection kernel\n",
        "import numpy as np\n",
        "\n",
        "def histogram_intersection_kernel(X, Y):\n",
        "   K = np.zeros((X.shape[0], Y.shape[0]), dtype=np.float64)\n",
        "   for i, x in enumerate(X):\n",
        "      for j, y in enumerate(Y):\n",
        "        K[i, j] = np.sum(np.minimum(x, y)) #Element-wise minimum of array elements.\n",
        "   return K\n",
        "   \n",
        "    \n"
      ],
      "id": "W8Psr-zYo1h3"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4f2b15cfc53a824470ce30452dac5c45",
          "grade": true,
          "grade_id": "cell-ce0523bb5bc169ef",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Ix7G6OhEo1h3"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "Ix7G6OhEo1h3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ab78f9115d80a9ca00d72f168f9c77ac",
          "grade": false,
          "grade_id": "cell-6c100514ed2bfb2b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "5HZMiVuNo1h3"
      },
      "source": [
        "## Question 11 (2 mark)\n",
        "Write a function `generalized_histogram_intersection_kernel(X, Y, alpha)` to compute Generalized Histogram Intersection Kernel which is computed by\n",
        "$$k(x, y)=\\sum_{i=1}^d \\min(|x_i|^\\alpha, |y_i|^\\alpha)$$\n",
        "where $d$ is the length of the feature vector.\n",
        "\n",
        "#### Inputs\n",
        "* `X` and `Y` are 2 dimensional numpy arrays of shape $M \\times d$ and $N \\times d$ respectively of data type `int64`.\n",
        "* `alpha` is a real number of data type `float`.\n",
        "\n",
        "#### Outputs\n",
        "* This function should return a 2 dimensional numpy array of shape $M \\times N$ of data type `float64`.\n",
        "\n",
        "#### Data\n",
        "* There is no specific data for this question. However, you can create your own data `X` and `Y` satisfying the input criteria.\n",
        "\n",
        "#### Marking Criteria\n",
        "* You will obtain full marks if and only if the kernel matrix calculated by your function exactly matches with the correct one. There is no partial marking for this question."
      ],
      "id": "5HZMiVuNo1h3"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bc745c147a78cfb514f8e69d108535e5",
          "grade": false,
          "grade_id": "cell-002da2406b7fde7e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "UiBicIF7o1h4"
      },
      "outputs": [],
      "source": [
        "def generalized_histogram_intersection_kernel(X, Y, alpha): \n",
        "\n",
        "  K = np.zeros((X.shape[0], Y.shape[0]), dtype=np.float64)\n",
        "  for i, x in enumerate(X):\n",
        "      for j, y in enumerate(Y):\n",
        "        K[i, j] = np.sum(np.minimum(np.abs(x)**alpha, np.abs(y)**alpha)) #Element-wise minimum of array elements.\n",
        "  return K\n",
        "    "
      ],
      "id": "UiBicIF7o1h4"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cd3fc9ed6d3f5412e4950d0ee4827351",
          "grade": true,
          "grade_id": "cell-7e0c00f42e3b8872",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "jnmiPSamo1h4"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "jnmiPSamo1h4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ff55f2423a1b70608faed1cf54bda8d9",
          "grade": false,
          "grade_id": "cell-8a3372fac153b97d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Pt5dYdWho1h4"
      },
      "source": [
        "## Question 12 (2 mark)\n",
        "Write a function `train_gram_matrix(X_tr, X_te)` which will compute the train gram matrix using the Histogram Intersection Kernel implemented above.\n",
        "\n",
        "#### Inputs\n",
        "* `X_tr` and `X_te` are 2 dimensional numpy arrays of shape $M \\times d$ and $N \\times d$ respectively of data type `int64`.\n",
        "\n",
        "#### Outputs\n",
        "* This function should return a 2 dimensional numpy array of data type `float64`.\n",
        "\n",
        "#### Data\n",
        "* There is no specific data for this question. However, you can create your own data `X_tr` and `X_te` satisfying the input criteria.\n",
        "\n",
        "#### Marking Criteria\n",
        "* You will obtain full marks if and only if the kernel matrix calculated by your function exactly matches with the correct one. There is no partial marking for this question."
      ],
      "id": "Pt5dYdWho1h4"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bae5c8df3bf57e83ba67d8a61cfc6755",
          "grade": false,
          "grade_id": "cell-093d79e82cd16400",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "4F7okonBo1h4"
      },
      "outputs": [],
      "source": [
        "# Train gram matrix\n",
        "def train_gram_matrix(X_tr, X_te):                   \n",
        "    hist_data = histogram_intersection_kernel(X_tr, X_te)\n",
        "    return hist_data"
      ],
      "id": "4F7okonBo1h4"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0746fb194b6205b660955700980dce15",
          "grade": true,
          "grade_id": "cell-7e328f69d465734e",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "FA2lW9k3o1h4"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "FA2lW9k3o1h4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5426664c014ea26eb80ffd37c9f6f3b0",
          "grade": false,
          "grade_id": "cell-ec232a09ce979306",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2JVrbhUno1h4"
      },
      "source": [
        "## Question 13 (2 mark)\n",
        "Write a function `test_gram_matrix(X_tr, X_te)` which will compute the test gram matrix using the Histogram Intersection Kernel implemented above.\n",
        "\n",
        "#### Inputs\n",
        "* `X_tr` and `X_te` are 2 dimensional numpy arrays of shape $M \\times d$ and $N \\times d$ respectively of data type `int64`.\n",
        "\n",
        "#### Outputs\n",
        "* This function should return a 2 dimensional numpy array of data type `float64`.\n",
        "\n",
        "#### Data\n",
        "* There is no specific data for this question. However, you can create your own data `X_tr` and `X_te` satisfying the input criteria.\n",
        "\n",
        "#### Marking Criteria\n",
        "* You will obtain full marks if and only if the kernel matrix calculated by your function exactly matches with the correct one. There is no partial marking for this question."
      ],
      "id": "2JVrbhUno1h4"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "800c6475fa61afc39a0c70c331ed6d2d",
          "grade": false,
          "grade_id": "cell-b5b0e0bdc5001b77",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "JuyNU2O5o1h4"
      },
      "outputs": [],
      "source": [
        "# Test gram matrix\n",
        "def test_gram_matrix(X_tr, X_te):\n",
        "  hist_data = histogram_intersection_kernel(X_tr, X_te)\n",
        "  return hist_data"
      ],
      "id": "JuyNU2O5o1h4"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b1fe78761cd2086fd3400f33f3104049",
          "grade": true,
          "grade_id": "cell-bf86e4f46bfd3819",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "sSDdD7zro1h5"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "sSDdD7zro1h5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "97747b2b5d4dd0396899d89406689d08",
          "grade": false,
          "grade_id": "cell-8a10c608cb9a6a0d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "hZx-aLQjo1h5"
      },
      "source": [
        "## Question 14 (5 marks)\n",
        "Write a function `train_cnn(model, train_loader)` to train the following version of the Residual Network (ResNet) model on the [EXCV10](https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip) (Exeter Computer Vision 10) dataset (available at this [link](https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip)). At the end of the training, this function should save the best weights of the trained CNN at: `data/weights_resnet.pth`. The [EXCV10](https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip) dataset contains 10000 images from 10 classes which are further split into train (available at `train/` folder; total 8000 images with 800 images/class) and validation (available at `val/` folder; total 2000 images with 200 images/class) sets. For training your model, please feel free to decide your optimal hyperparameters, such as the number of epochs, type of optimizers, learning rate scheduler etc within the function, which can be done to optimize the performance of the model on the validation set.\n",
        "#### Inputs\n",
        "* `model` is an instantiation of ResNet class which can be created as follows: `ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=num_classes)`. An example of this can be found in the snippet in the following cell.\n",
        "* `train_loader` is the training data loader. You can create the dataset and data loader for your training following the example in the cell below. Feel free to try other data augmentation and regularization techniques to train a better model.\n",
        "\n",
        "#### Outputs\n",
        "* This function should not necessarily return any output, instead it should save your best model at `data/weights_resnet.pth`.\n",
        "\n",
        "#### Data\n",
        "* You can train your model on the data available at https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip. As EXCV10 dataset is quite large in size, donot upload it with your submission.\n",
        "\n",
        "#### Marking Criteria\n",
        "* You will obtain full marks if the model weights saved at `data/weights_resnet.pth` can be loaded to a new instantiation of the model `ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=num_classes)`. You will not get any mark if your model is missing or saved in a different location or it cannot be loaded to the aforementioned model instance. Additionally, the quality of your trained model will be examined in the next question."
      ],
      "id": "hZx-aLQjo1h5"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "122e1f37baffd76d0bc3bdd94790e4ad",
          "grade": false,
          "grade_id": "cell-7b71cb4a01ea3b5a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "EE4OxpcSo1h5",
        "outputId": "079fac10-853f-4ef1-fb6d-0d2d0c4d9e60"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-1d9b1831dc7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         )\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m     ) -> None:\n\u001b[1;32m    144\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train/'"
          ]
        }
      ],
      "source": [
        "# ResNet model\n",
        "from ca_utils import ResNet, BasicBlock\n",
        "model = ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=1000)  # change num_classes if needed, this is an example\n",
        "\n",
        "# Dataset\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Vanilla image transform\n",
        "image_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Dataset\n",
        "import torchvision\n",
        "train_data = torchvision.datasets.ImageFolder('train/', transform=image_transform)\n",
        "\n",
        "# Data loader\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)"
      ],
      "id": "EE4OxpcSo1h5"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "73bc97a1efa842e98a676bef9ebc57bc",
          "grade": false,
          "grade_id": "cell-4d32274b0fd42843",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "99CjJpclo1h5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "# N_epochs = 100\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "# Train CNN\n",
        "def train_cnn(model, train_loader):\n",
        "  \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01) # ADAM optimizer is faster than SGD\n",
        "    N_epochs = 100\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "    for epoch in range(N_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          \n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward() # to calculate gradients backwards\n",
        "          optimizer.step() # update the values of neurons :\n",
        "          \n",
        "          # print statistics\n",
        "          running_loss += loss.item()\n",
        "      print(f'[Epoch : {epoch + 1}] loss: {running_loss / (i+1):.3f}')\n",
        "      scheduler.step()\n",
        "    print('Finished Training')\n",
        "    PATH = 'data/weights_resnet.pth'\n",
        "    torch.save(model.state_dict(), PATH)"
      ],
      "id": "99CjJpclo1h5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ca38131593368d47c549d2cefd0732ed",
          "grade": true,
          "grade_id": "cell-ac88643e76933161",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "KH-Lb5mio1h5"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "KH-Lb5mio1h5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5857290bcadd91f3884e8fa5a97a6172",
          "grade": false,
          "grade_id": "cell-8f3e37cc7454f448",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oz9TbFCxo1h5"
      },
      "source": [
        "## Question 15 (14 marks)\n",
        "Write a function `test_cnn(model, test_loader)` which will return the predicted labels by the `model` that you trained in the previous question for all the images supplied in the `test_loader` object. The test set will contain 3000 images (300 images/class) from the same distribution as of the [EXCV10](https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip) dataset.\n",
        "\n",
        "#### Inputs\n",
        "* `model` is an instantiation of ResNet class which can be created as follows `ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=num_classes)`. An example of this can be found in the cell below.\n",
        "* `test_loader` is the data loader containing test data. The test data loader can be created following the example in the cell below. We will only use vanilla transformation to the test dataset.\n",
        "\n",
        "#### Outputs\n",
        "* This function should return a 1 dimensional numpy array of data type `int64` containing the predicted labels of the images in the `test_loader` object.\n",
        "\n",
        "#### Data\n",
        "* You can test your model on the `val` set of the data available at https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/EXCV10.zip. As EXCV10 dataset is quite large in size, please donot upload it with your submission.\n",
        "\n",
        "#### Marking Criteria\n",
        "* Your model will be tested based on average classification accuracy on a test set of 3000 images (300 images/class). You will obtain 50% marks if the obtained accuracy of your model on the test set is greater than or equal to 50%, 60% marks if your model obtains 55% accuracy or more, 70% marks if your model gets 60% accuracy or more, 80% marks if your model acquires 65% accuracy or more, 90% marks if your model wins 70% accuracy or more, and full marks if your model secures 75% accuracy or more. You will not obtain any mark if your model can not achieve 50% accuracy."
      ],
      "id": "oz9TbFCxo1h5"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e6ee751811459073106480dbf7035c6d",
          "grade": false,
          "grade_id": "cell-418180b7807c1d03",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "A56DDUGao1h6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "559694e8-18f7-40bf-af92-7f0f2bbef93c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-2bf9a82fa606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEXCV10TestImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-2bf9a82fa606>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEXCV10TestImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXCV10TestImageFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         )\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m     ) -> None:\n\u001b[1;32m    144\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'val/'"
          ]
        }
      ],
      "source": [
        "# Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "# The following data generator is similar to 'ImageFolder',\n",
        "# the only difference is that it doesn't return the target\n",
        "# label. This is why the following 'EXCV10TestImageFolder' \n",
        "# data generator will be used for testing.\n",
        "class EXCV10TestImageFolder(datasets.ImageFolder):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(EXCV10TestImageFolder, self).__init__(*args, **kwargs)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.imgs[index][0]\n",
        "        pic = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(pic)\n",
        "        return img\n",
        "    \n",
        "# Vanilla image transform\n",
        "image_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    \n",
        "# Dataset\n",
        "test_data = EXCV10TestImageFolder('val/', transform=image_transform)\n",
        "\n",
        "# Data loader\n",
        "from torch.utils.data import DataLoader\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "id": "A56DDUGao1h6"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "163d2867fa72a1da3b211a64c3c30d58",
          "grade": false,
          "grade_id": "cell-4bc52a72e10b0231",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "frB7bOK-o1h6"
      },
      "outputs": [],
      "source": [
        "# Test CNN\n",
        "\n",
        "def test_cnn(model, test_loader):\n",
        "    model.eval()\n",
        "    out_labels = []\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            out_labels.extend(predicted.cpu().detach().numpy().tolist())\n",
        "    out = np.asarray(out_labels, dtype=np.int64).reshape(len(out_labels),)\n",
        "    model.train()\n",
        "    return out"
      ],
      "id": "frB7bOK-o1h6"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f210902e23708dfe0afd9a7dfdf75da9",
          "grade": true,
          "grade_id": "cell-d9ed0c43b4c6e040",
          "locked": true,
          "points": 7,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "NJO4-eIQo1h6"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "NJO4-eIQo1h6"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3d7c56206e116902af4703c6d032ce94",
          "grade": true,
          "grade_id": "cell-a603726e91aa21a6",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7pkvF7Cyo1h6"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "7pkvF7Cyo1h6"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f9bd5388d763b9d43bd460a7912a1094",
          "grade": true,
          "grade_id": "cell-57f81fad25de6e73",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "RM25SzKpo1h6"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "RM25SzKpo1h6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95d2210ed867298b61e7dca1ee1ceb44",
          "grade": true,
          "grade_id": "cell-c32643caf64fffd2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Sk2tGvT9o1h6"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "Sk2tGvT9o1h6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "aa93eb8b8f70dd88387dc41f150596c1",
          "grade": true,
          "grade_id": "cell-f47be569bde61e82",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "PZl621s3o1h6"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "PZl621s3o1h6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "936816a7604d0a414b66f29b718b6dad",
          "grade": true,
          "grade_id": "cell-466641090eb4b8bb",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "T_GAVERRo1h7"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "T_GAVERRo1h7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a846d7ba9dfc1a6412374460791992b4",
          "grade": false,
          "grade_id": "cell-c0c5a0af68bfac8d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "v95jIGpwo1h7"
      },
      "source": [
        "## Question 16 (18 marks)\n",
        "Write a function `count_masks(dataset)` which will count the number of faces correctly wearing mask (`with_mask` class), without mask (`without_mask` class) and incorrectly wearing mask (`mask_weared_incorrect` class) in the list of images `dataset` which is an instantiation of the `MaskedFaceTestDataset` class shown below. (**Hint**: You are expected to implement a 3 class (4 class with background) masked face detector which can detect the aforementioned categories of objects in a given image. However, you are absolutely free to be more innovative and come out with different solutions for this problem.)\n",
        "\n",
        "**Note:** If you need to upload a file larger than 100MB limit, please upload that file in an external storage and put that link in a README to be uploaded with your submission.\n",
        "\n",
        "<img src=\"data/mask.png\" alt=\"Mask\" width=\"800\"/>\n",
        "\n",
        "#### Inputs\n",
        "* `dataset` is an object of the `MaskedFaceTestDataset` class shown in the cell below.\n",
        "\n",
        "#### Outputs\n",
        "* This function should return a 2 dimensional numpy array of shape $N \\times 3$ of data type `int64` whose values should respectively indicate the number of faces wearing mask, without mask and incorrectly wearing mask. Here $N$ is the total number of images.\n",
        "\n",
        "#### Data\n",
        "* You can train and test your model on the data available at https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/MaskedFace.zip. This dataset contains some images and corresponding annotations (locations together with category information) of masked faces, which are split into `train` and `val` subsets. You can train your model on `train` set and decide your hyperparameters on the `val` sets. As MaskedFace dataset is quite large in size, please donot upload it with your submission.\n",
        "\n",
        "#### Marking Criteria\n",
        "* The evaluation will be done based on Mean Absolute Percentage Error (MAPE) which is defined as follows:\n",
        "$$\\text{MAPE} = \\frac{1}{n}\\sum_{t=1}^n \\left|\\frac{A_t - P_t}{\\max(A_t, 1)}\\right| \\times 100 $$\n",
        "where $A_t$ is the true number and $P_t$ is the predicted number of the corresponding class $t$ in an image. For each image in `dataset`, MAPE will be computed, which will be averaged over all the images in `dataset`. You will obtain 50% marks if the obtained average MAPE of your model on the test set is lower than or equal to 30%, 62.5% marks if your model obtains 25% MAPE or less, 75% marks if your model gets 20% MAPE or less, 87.5% marks if your model acquires 15% MAPE or less, and full marks if your model secures 10% MAPE or less. You will not obtain any mark if your model can not achieve minimum 30% MAPE."
      ],
      "id": "v95jIGpwo1h7"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4d0e94a10d676a58553501127d98fd5d",
          "grade": false,
          "grade_id": "cell-a5f52ba49b912893",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "M9jqYw5xo1h7",
        "outputId": "316a9780-e765-434d-cc3d-f74d965fdcbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v6.1-214-g541a5b7 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (4 CPUs, 25.5 GB RAM, 38.8/166.8 GB disk)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-9662dac694ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskedFaceTestDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'yolo_data/val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mmape_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m---> 98\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ],
      "source": [
        "\n",
        "# Dataset\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class MaskedFaceTestDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        super(MaskedFaceTestDataset, self).__init__()\n",
        "        self.imgs = sorted(glob.glob(os.path.join(root + '/' + 'images', '*.png')))\n",
        "        \n",
        "        # support for labels\n",
        "        self.annotation_files = sorted(glob.glob(os.path.join(root + '/' + 'labels', '*.txt')))\n",
        "\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.imgs[index]\n",
        "        annot_path = self.annotation_files[index]\n",
        "\n",
        "        ########## read annotation ################\n",
        "        with open(annot_path, 'r') as t:\n",
        "          annotations = t.readlines()\n",
        "\n",
        "        all_labels = {}\n",
        "        for f in annotations:\n",
        "          cls_ = int(f[0].strip().split(' ')[0]) # get class id\n",
        "          all_labels[cls_] = all_labels.get(cls_,0) + 1 # count class id\n",
        "        \n",
        "\n",
        "        original_img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        ### additional support for opencv\n",
        "        img = np.asarray(original_img)\n",
        "        img = cv2.resize(img, (960,960))  # resizing to 960x960\n",
        "        # img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
        "        img = img.transpose(2, 0, 1)\n",
        "        img = np.ascontiguousarray(img)\n",
        "        img = torch.from_numpy(img)\n",
        "        img =  img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0   \n",
        "        \n",
        "        #if img.ndimension() == 3:\n",
        "        #   img = img.unsqueeze(0)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, all_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "\n",
        "### Load model \n",
        "! wget https://github.com/ultralytics/yolov5/archive/refs/heads/master.zip\n",
        "! unzip !unzip master.zip -d ./yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from utils.general import non_max_suppression, scale_coords\n",
        "\n",
        "# Load model\n",
        "\n",
        "weights = '/content/data/best.pt'\n",
        "yolo_model = torch.load(weights, map_location='cpu')['model'].float()  # load to FP32\n",
        "yolo_model.eval()\n",
        "\n",
        "def run_inference(img):\n",
        "  # Inference\n",
        "  pred = yolo_model(img, augment=False)[0]\n",
        "  pred = non_max_suppression(pred, conf_thres = 0.4, iou_thres  = 0.3)\n",
        "\n",
        "  boxes = []\n",
        "  scores = []\n",
        "  classes = []\n",
        "  for i, det in enumerate(pred):  # detections per image\n",
        "      # save_path = 'draw/' + image_id + '.jpg'\n",
        "      if det is not None and len(det):\n",
        "          # Rescale boxes from img_size to im0 size\n",
        "          #det[:, :4] = scale_coords(img.shape[2:], det[:, :4], original_img.shape).round()\n",
        "\n",
        "          # Write results\n",
        "          for *xyxy, conf, cls in det:\n",
        "              boxes.append([int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3])])\n",
        "              scores.append(conf)\n",
        "              classes.append(cls)\n",
        "\n",
        "  return boxes, scores, classes\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "test_data = MaskedFaceTestDataset(root = 'yolo_data/val')\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "mape_all = []\n",
        "for data in test_loader:\n",
        "    \n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "    boxes, scores, classes = run_inference(inputs)\n",
        "    actual_classes = sum([v for k,v in labels.items()])\n",
        "    mape = abs(actual_classes - len(classes))/ max(actual_classes, 1)\n",
        "    mape_all.append(mape.numpy())\n",
        "\n"
      ],
      "id": "M9jqYw5xo1h7"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "916d53421e684eac2a7466b5cf679d81",
          "grade": false,
          "grade_id": "cell-04285181322066d5",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "ZyvhYu6Jo1h7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "# Count masked faces\n",
        "def count_masks(test_dataset):\n",
        "    \n",
        "    outputs = []\n",
        "    for i in range(len(test_dataset)):\n",
        "      img = test_dataset[i].unsqueeze(0)\n",
        "      boxes, scores, classes = run_inference(img)\n",
        "     \n",
        "      #refactoring\n",
        "      classes = [int(c.item()) for c in classes]\n",
        "      outputs.append([classes.count(i) for i in [0,1,2]])\n",
        "\n",
        "    return np.asarray(outputs)"
      ],
      "id": "ZyvhYu6Jo1h7"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "adcbc8ce33e1f3854a02e13aa9b9f656",
          "grade": true,
          "grade_id": "cell-5f48c3e6ef3435ea",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "j-rcqCZio1h7"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "j-rcqCZio1h7"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "53b4032d252d8eb9b0edd45597c1219d",
          "grade": true,
          "grade_id": "cell-c64fa7ff5042255c",
          "locked": true,
          "points": 9,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "FyG4DuBgo1h7"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "FyG4DuBgo1h7"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b98d3e950240c7144572ab5ed2f7bd42",
          "grade": true,
          "grade_id": "cell-e3fcd145196897b8",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DSiwP4K3o1h7"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "DSiwP4K3o1h7"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1be857d60af098552c0277ae5823b978",
          "grade": true,
          "grade_id": "cell-19dcf73f57f687fa",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "rOQzf_gmo1h7"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "rOQzf_gmo1h7"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "70b1a275601c17c9babf15bed48264c9",
          "grade": true,
          "grade_id": "cell-a8faf4bd17f0dc76",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MgaFGFtRo1h8"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "MgaFGFtRo1h8"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "777aaa29a418de8b3aba352f2c0f5964",
          "grade": true,
          "grade_id": "cell-cb29738c18d73803",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "T2RzOV9Vo1h8"
      },
      "outputs": [],
      "source": [
        "# This cell is reserved for the unit tests. Please leave this cell as it is."
      ],
      "id": "T2RzOV9Vo1h8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "77448310aeff20b40896c71d0fc0c446",
          "grade": false,
          "grade_id": "cell-fd2525614f9ebd17",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "UemT9WtLo1h8"
      },
      "source": [
        "## Checkpoints\n",
        "\n",
        "Checkpoints are very **IMPORTANT** for this course assessment, which will ensure your solutions are syntactically correct. In other words, this step will make sure that you have implemented all the required functions and their expected outputs are syntactically correct i.e. the outputs are consistent from shape, datatype and dimensionality perspective. However, passing these checkpoints will not ensure your implementations or answers are correct, which will be further checked via hidden unit tests after the submission. Please run the following two cells sequentially to run the checkpoints. \n",
        "\n",
        "Please note that the execution of the second cell **should not take more than one minute**, which is actually the last checkpoint.\n",
        "\n",
        "Initially, when none of the above functions is implemented, executing the following two cells should produce the following output:\n",
        "<div style=\"text-align: left;\"><img src=\"data/initial_log.png\" alt=\"Initial Log\" width=\"700\"/></div>\n",
        "\n",
        "Once you have all the required functions correctly implemented, executing the following two cells should produce the following output:\n",
        "<div style=\"text-align: left;\"><img src=\"data/final_log.png\" alt=\"Final Log\" width=\"800\"/></div>\n",
        "\n",
        "**Note:** If you are working on Google Colab, the first cell (below) may not execute as par the expectation, for Colab's incompatibility with Javascript. In that case, please consider running all the answer cells manually before running the second cell."
      ],
      "id": "UemT9WtLo1h8"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f1a04f19bc0227af70f4c1999f7e8209",
          "grade": false,
          "grade_id": "cell-4a11661adce06bcb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WSlbMul0o1h8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e80a5aaa-44db-461a-8c3d-cc230c2134ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "Jupyter.notebook.execute_cells([2, 3, 6, 9, 12, 15, 18, 28, 31, 39, 45, 48, 51, 54, 58, 62, 71])"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# This cell will run all the answer cells.\n",
        "# This cell does not work on Colab for its\n",
        "# incompatibility with Javascript, so if you\n",
        "# are on Google Colab, please consider running \n",
        "# the cells with answers manually before running\n",
        "# next cells.\n",
        "%reset -f\n",
        "from IPython.display import Javascript\n",
        "display(Javascript(\"Jupyter.notebook.execute_cells([2, 3, 6, 9, 12, 15, 18, 28, 31, 39, 45, 48, 51, 54, 58, 62, 71])\"))"
      ],
      "id": "WSlbMul0o1h8"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "685bb9bd3106ff6bad091888008377d3",
          "grade": false,
          "grade_id": "cell-b2d3d17d61b22258",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_i3LhSfo1h8",
        "outputId": "1c269db7-1b9a-4b9a-f136-20e0b8b3dc9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mQ1. The 'add_gaussian_noise' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ2. The 'add_speckle_noise' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ3. The 'cal_image_hist' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ4. The 'compute_gradient_magnitude' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ5. The 'compute_gradient_direction' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ6. The 'detect_harris_corner' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ7. The 'compute_sift' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ8. The 'match_features' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ9. The 'make_bovw_spatial_histogram' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ10. The 'histogram_intersection_kernel' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ11. The 'generalized_histogram_intersection_kernel' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ12. The 'train_gram_matrix' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ13. The 'test_gram_matrix' function cannot be found.\u001b[0m\n",
            "\u001b[31mQ14. The 'train_cnn' function cannot pass the initial test.\u001b[0m\n",
            "\u001b[31mQ15. The 'test_cnn' function cannot pass the initial test.\u001b[0m\n",
            "\u001b[31mQ16. The 'count_masks' function cannot be found.\u001b[0m\n",
            "\u001b[32mExecution took 00:00:00 which met the time criteria.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# This cell will run the initial tests for questions\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "from termcolor import colored\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "from ca_utils import load_interest_points\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Test data\n",
        "\n",
        "class CheckPointDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "    def __getitem__(self, item):\n",
        "        return self.data[item]\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "test_data = CheckPointDataset(torch.rand(8, 3, 224, 224))\n",
        "test_loader = DataLoader(test_data, batch_size=2)\n",
        "p1 = np.random.randint(0, 226, (100, 2), dtype=\"uint8\")\n",
        "p2 = np.random.randint(0, 226, (100, 2), dtype=\"uint8\")\n",
        "R1 = np.array([[0.9903, 0.0000, -0.1392], [0.0242, 0.9848, 0.1720]], dtype=np.float32)\n",
        "R2 = np.array([[1.0000, 0.0000, 0.00000], [0.0000, 0.9848, 0.1736]], dtype=np.float32)\n",
        "T1 = np.array([500, 160], dtype=np.float32)\n",
        "T2 = np.array([500, 160], dtype=np.float32)\n",
        "\n",
        "# Q1 initial test\n",
        "try:\n",
        "    output_1 = add_gaussian_noise(dummy_1, 0.0, 0.0)\n",
        "    if isinstance(output_1, np.ndarray) and output_1.shape == dummy_1.shape and output_1.dtype == \"float32\":\n",
        "        print(colored(\"Q1. The 'add_gaussian_noise' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q1. The 'add_gaussian_noise' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q1. The 'add_gaussian_noise' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q2 initial test\n",
        "try:\n",
        "    output_2 = add_speckle_noise(dummy_1, 0.0, 0.0)\n",
        "    if isinstance(output_2, np.ndarray) and output_2.shape == dummy_1.shape and output_2.dtype == \"float32\":\n",
        "        print(colored(\"Q2. The 'add_speckle_noise' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q2. The 'add_speckle_noise' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q2. The 'add_speckle_noise' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q3 initial test\n",
        "try:\n",
        "    output_3 = cal_image_hist(dummy_2)\n",
        "    if isinstance(output_3, np.ndarray) and output_3.ndim == 1 and output_3.shape[0] > 1 and output_3.dtype == \"int64\":\n",
        "        print(colored(\"Q3. The 'cal_image_hist' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q3. The 'cal_image_hist' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q3. The 'cal_image_hist' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q4 initial test\n",
        "try:\n",
        "    output_4 = compute_gradient_magnitude(dummy_2, k, k)\n",
        "    if isinstance(output_4, np.ndarray) and output_4.shape == (750, 750) and output_4.dtype == \"float64\":\n",
        "        print(colored(\"Q4. The 'compute_gradient_magnitude' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q4. The 'compute_gradient_magnitude' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q4. The 'compute_gradient_magnitude' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q5 initial test\n",
        "try:\n",
        "    output_5 = compute_gradient_direction(dummy_2, k, k)\n",
        "    if isinstance(output_5, np.ndarray) and output_5.shape == (750, 750) and output_5.dtype == \"float64\":\n",
        "        print(colored(\"Q5. The 'compute_gradient_direction' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q5. The 'compute_gradient_direction' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q5. The 'compute_gradient_direction' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q6 initial test\n",
        "try:\n",
        "    output_6 = detect_harris_corner(shapes)\n",
        "    if isinstance(output_6, np.ndarray) and output_6[0].shape[0] > 1 and output_6[0].dtype == \"int64\":\n",
        "        print(colored(\"Q6. The 'detect_harris_corner' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q6. The 'detect_harris_corner' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q6. The 'detect_harris_corner' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q7 initial test\n",
        "try:\n",
        "    output_8 = compute_sift(notre_dame_1, x1, y1)\n",
        "    if isinstance(output_8, np.ndarray) and output_8.ndim == 2 and output_8.dtype == \"float64\":\n",
        "        print(colored(\"Q7. The 'compute_sift' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q7. The 'compute_sift' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q7. The 'compute_sift' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q8 initial test\n",
        "try:\n",
        "    output_9 = compute_sift(notre_dame_2, x2, y2)\n",
        "    output_10 = match_features(output_8, output_9, x1, y1, x2, y2)\n",
        "    if isinstance(output_10, tuple) and isinstance(output_10[0], np.ndarray) and output_10[0].ndim == 2 and output_10[0].dtype == \"int64\" and isinstance(output_10[1], np.ndarray) and output_10[1].ndim == 1 and output_10[1].dtype == \"float64\":\n",
        "        print(colored(\"Q8. The 'match_features' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q8. The 'match_features' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q8. The 'match_features' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q9 initial test\n",
        "try:\n",
        "    output_12 = make_bovw_spatial_histogram(notre_dame_1, locations, clusters, [2, 2])\n",
        "    if isinstance(output_12, np.ndarray) and output_12.ndim == 1 and output_12.shape[0] > 1 and output_12.dtype == \"int64\":\n",
        "        print(colored(\"Q9. The 'make_bovw_spatial_histogram' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q9. The 'make_bovw_spatial_histogram' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q9. The 'make_bovw_spatial_histogram' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q10 initial test\n",
        "try:\n",
        "    output_13 = histogram_intersection_kernel(U, V)\n",
        "    if isinstance(output_13, np.ndarray) and output_13.ndim == 2 and output_13.dtype == \"float64\":\n",
        "        print(colored(\"Q10. The 'histogram_intersection_kernel' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q10. The 'histogram_intersection_kernel' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q10. The 'histogram_intersection_kernel' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q11 initial test\n",
        "try:\n",
        "    output_14 = generalized_histogram_intersection_kernel(U, V, 0.6)\n",
        "    if isinstance(output_14, np.ndarray) and output_14.ndim == 2 and output_14.dtype == \"float64\":\n",
        "        print(colored(\"Q11. The 'generalized_histogram_intersection_kernel' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q11. The 'generalized_histogram_intersection_kernel' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q11. The 'generalized_histogram_intersection_kernel' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q12 initial test\n",
        "try:\n",
        "    output_15 = train_gram_matrix(U, V)\n",
        "    if isinstance(output_15, np.ndarray) and output_15.ndim == 2 and output_15.dtype == \"float64\":\n",
        "        print(colored(\"Q12. The 'train_gram_matrix' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q12. The 'train_gram_matrix' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q12. The 'train_gram_matrix' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q13 initial test\n",
        "try:\n",
        "    output_16 = test_gram_matrix(U, V)\n",
        "    if isinstance(output_16, np.ndarray) and output_16.ndim == 2 and output_16.dtype == \"float64\":\n",
        "        print(colored(\"Q13. The 'test_gram_matrix' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q13. The 'test_gram_matrix' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q13. The 'test_gram_matrix' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Q14 initial test\n",
        "flag1 = os.path.isfile(\"data/weights_resnet.pth\")\n",
        "try:\n",
        "    from ca_utils import ResNet, BasicBlock\n",
        "    model = ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=10)\n",
        "    cp = torch.load(\"data/weights_resnet.pth\", map_location=torch.device(\"cpu\"))\n",
        "    model.load_state_dict(cp)\n",
        "    flag2 = True\n",
        "except (FileNotFoundError):\n",
        "    flag2 = False\n",
        "if flag1 and flag2:\n",
        "    print(colored(\"Q14. The 'train_cnn' function has passed the initial test.\", \"green\"))\n",
        "else:\n",
        "    print(colored(\"Q14. The 'train_cnn' function cannot pass the initial test.\", \"red\"))\n",
        "\n",
        "# Q15 initial test\n",
        "try:\n",
        "    output_18 = test_cnn(model, test_loader)\n",
        "    flag3 = True\n",
        "except (NotImplementedError, NameError):\n",
        "    flag3 = False\n",
        "if flag3 and isinstance(output_18, np.ndarray) and output_18.ndim == 1 and output_18.shape == (len(test_data),) and output_18.dtype == \"int64\":\n",
        "    print(colored(\"Q15. The 'test_cnn' function has passed the initial test.\", \"green\"))\n",
        "else:\n",
        "    print(colored(\"Q15. The 'test_cnn' function cannot pass the initial test.\", \"red\"))\n",
        "\n",
        "# Q16 initial test\n",
        "try:\n",
        "    output_19 = count_masks(test_data)\n",
        "    if isinstance(output_19, np.ndarray) and output_19.shape == (len(test_data), 3) and output_19.dtype == \"int64\":\n",
        "        print(colored(\"Q16. The 'count_masks' function has passed the initial test.\", \"green\"))\n",
        "    else:\n",
        "        print(colored(\"Q16. The 'count_masks' function cannot pass the initial test.\", \"red\"))\n",
        "except (NotImplementedError, NameError):\n",
        "    print(colored(\"Q16. The 'count_masks' function cannot be found.\", \"red\"))\n",
        "\n",
        "# Execution time should be less than 1 minute\n",
        "tot_time = time.time() - start_time\n",
        "if tot_time > 60:\n",
        "    print(colored(\"Execution took {} which is higher than the time limit and should be within {}.\".format(time.strftime(\"%H:%M:%S\", time.gmtime(tot_time)), time.strftime(\"%H:%M:%S\", time.gmtime(60.0))), \"red\"))\n",
        "else:\n",
        "    print(colored(\"Execution took {} which met the time criteria.\".format(time.strftime(\"%H:%M:%S\", time.gmtime(tot_time))), \"green\"))"
      ],
      "id": "Z_i3LhSfo1h8"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4_hqZby9pwey"
      },
      "id": "4_hqZby9pwey",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of CA.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}